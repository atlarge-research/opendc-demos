{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenDC\n",
    "\n",
    "Data centers are becoming an increasingly large contributor to the global carbon footprint. However, because of a lack of tools / guidelines, it has been challenging to optimize data centers for carbon emissions. This is amplified by the fact that running experiments on data centers is both expansive and time consuming. \n",
    "\n",
    "OpenDC is a event-based discrete data center simulator. Using such a tool we can do experiments on data centers in a cost-effective and flexible way. In this demo we are going to compare a small and large data center using OpenDC. We are comparing the data centers in terms of performance and sustainability.\n",
    "\n",
    "You can read more about OpenDC [here](https://opendc.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Topology\n",
    "\n",
    "To run a simulation, OpenDC needs a definition of the data center, which we call the topology. The topology of a data center can influence its performance and sustainability greatly. It determines which tasks can be run, how efficiently they are run, and if they can be executed in parallel.\n",
    "\n",
    "The topology of datacenter is provided using a JSON file. This file defines how many clusters are available, the hosts they contain, and what type of hosts they are. In this demo we compare the performance of two topologies: [small](topologies/1.demo_basic/large_topology.json) and [here](topologies/1.demo_basic/large_topology.json) which can both be found in the resources/topologies folder. The small topology is shown below\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"clusters\": [\n",
    "        {\n",
    "            \"name\": \"C01\",\n",
    "            \"hosts\": [\n",
    "                {\n",
    "                    \"name\": \"H01\",\n",
    "                    \"count\": 1,\n",
    "                    \"cpu\": {\n",
    "                        \"coreCount\": 16,\n",
    "                        \"coreSpeed\": 3300\n",
    "                    },\n",
    "                    \"memory\": {\n",
    "                        \"memorySize\": 140457600000\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "The small data center contains only a single cluster *C01*, which contains a single host *H01*. Host *H01* constains two CPUs with 16 cores running at 3200 Mhz, and has a memory of 140457600000 Bytes.\n",
    "\n",
    "*Exercise 1:* Can you find out what hardware is contained in the large topology located [here](topologies/1.demo_basic/large_topology.json)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Workloads\n",
    "\n",
    "To run a simulation, OpenDC requires information on the type of workload to execute.\n",
    "\n",
    "\n",
    "The workload is provided using two files:\n",
    "<ul>\n",
    "    <li> **tasks.parquet** provides a general overview of the tasks executed during the workload. </li>\n",
    "    <li> **fragments.parquet** provides detailed information of each task during its runtime. </li>\n",
    "</ul>\n",
    "\n",
    "In this demo we are using running the [bitbrains-small](resources/workloads/bitbrains-small/) dataset as our workload. The bitbrains-small workload consist of 50 tasks with a runtime ranging from less than 7 days to more than 30 days. \n",
    "\n",
    "##### Lets have a look at the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T12:10:49.847317Z",
     "start_time": "2025-06-27T12:10:49.774798Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_tasks = pd.read_parquet(\"workload_traces/bitbrains-small/tasks.parquet\")\n",
    "df_fragments = pd.read_parquet(\"workload_traces/bitbrains-small/fragments.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_tasks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_fragments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Carbon Trace\n",
    "\n",
    "- Carbon Traces define the Carbon Intenisty of the available energy over time\n",
    "\n",
    "- Gathered using ENTSO-E\n",
    "\n",
    "- Specific to the location of the data center\n",
    "\n",
    "- Defined as a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_carbon = pd.read_parquet(\"carbon_traces/carbon_2022.parquet\")\n",
    "\n",
    "df_carbon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Experiment\n",
    "\n",
    "Finally, OpenDC needs an experiment file. The Experiment file describes what needs to be run, how, and when. An experiment is delilvered using a JSON file. The experiment we will use for this demo can be found [here](resources/experiments/1.demo_basic.json) and is shown below:\n",
    "\n",
    "Example Experiment:\n",
    "```json\n",
    "{\n",
    "    \"name\": \"1.demo_basic\",\n",
    "    \"topologies\": [\n",
    "        {\n",
    "            \"pathToFile\": \"topologies/1.demo_basic/small_topology.json\"\n",
    "        },\n",
    "        {\n",
    "            \"pathToFile\": \"topologies/1.demo_basic/large_topology.json\"\n",
    "        }\n",
    "    ],\n",
    "    \"workloads\": [\n",
    "        {\n",
    "            \"pathToFile\": \"workload_traces/bitbrains-small\",\n",
    "            \"type\": \"ComputeWorkload\"\n",
    "        }\n",
    "    ],\n",
    "    \"exportModels\": [\n",
    "        {\n",
    "            \"exportInterval\": 30000\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "The scenario file used in this demo defines four variables:\n",
    "- \"name\" defines where the ouput files will be stored\n",
    "- \"topologies\" defines the different topologies that will be used in the experiments\n",
    "- \"workloads\" defines what workloads will be run\n",
    "- \"exportModels\" defines how frequent OpenDC should export data\n",
    "\n",
    "\n",
    "Note: most of the variables in the scenario file are provided as lists. This makes it possible to run different experiments using the same scenario. Graph Greenifier will run all combinations of variables as seperate experiments. In this demo, we providee two topologies, and a single workload. This means that the same workload will be executed on the both scenarios, resulting in two results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Running an Experiment\n",
    "\n",
    "An experiment can be run directly from the terminal using the OpenDCExperimentRunner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "pathToScenario = \"experiments/1.demo_basic.json\"\n",
    "subprocess.run([\"OpenDCExperimentRunner/bin/OpenDCExperimentRunner\", \"--experiment-path\", pathToScenario])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df_host_small = pd.read_parquet(\"output/1.demo_basic/raw-output/0/seed=0/host.parquet\")\n",
    "df_power_small = pd.read_parquet(\"output/1.demo_basic/raw-output/0/seed=0/powerSource.parquet\")\n",
    "df_task_small = pd.read_parquet(\"output/1.demo_basic/raw-output/0/seed=0/task.parquet\")\n",
    "df_service_small = pd.read_parquet(\"output/1.demo_basic/raw-output/0/seed=0/service.parquet\")\n",
    "\n",
    "df_host_large = pd.read_parquet(\"output/1.demo_basic/raw-output/1/seed=0/host.parquet\")\n",
    "df_power_large = pd.read_parquet(\"output/1.demo_basic/raw-output/1/seed=0/powerSource.parquet\")\n",
    "df_task_large = pd.read_parquet(\"output/1.demo_basic/raw-output/1/seed=0/task.parquet\")\n",
    "df_service_large = pd.read_parquet(\"output/1.demo_basic/raw-output/1/seed=0/service.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Host\n",
    "- Information about the host at each timestamp. \n",
    "- Examples of metrics: \n",
    "    - cpu_utilization\n",
    "    - power_draw \n",
    "    - energy_usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The host file contains the following columns:\\n {np.array(df_host_small.columns)}\\n\")\n",
    "print(f\"The host file consist of {len(df_host_small)} samples\")\n",
    "df_host_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "- The task file contains all information about the different tasks at each timestamp. \n",
    "- Example use cases:\n",
    "    - when is a task run\n",
    "    - How long did it take\n",
    "    - on which host was a task executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The task file contains the following columns:\\n {np.array(df_task_small.columns)}\")\n",
    "print(f\"The task file consist of {len(df_task_small)} samples\")\n",
    "df_task_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power\n",
    "- The task file contains all information about the power sources at each timestamp. \n",
    "- Example use cases:\n",
    "    - What is the total energy used during the workload?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The task file contains the following columns:\\n {np.array(df_power_small.columns)}\")\n",
    "print(f\"The power file consist of {len(df_power_small)} samples\")\n",
    "df_power_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Service\n",
    "\n",
    "- The service file contains genaral information about the experiments. \n",
    "- Example uses:\n",
    "    - How many tasks are running?\n",
    "    - How many hosts are up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The service file contains the following columns:\\n {np.array(df_service_small.columns)}\")\n",
    "print(f\"The service file consist of {len(df_service_small)} samples\")\n",
    "df_service_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance\n",
    "\n",
    "- To properly compare the different experiments, we would like to aggregate them into meaningfull values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_small = pd.to_timedelta(df_service_small.timestamp.max() - df_service_small.timestamp.min(), unit=\"ms\")\n",
    "runtime_large = pd.to_timedelta(df_service_large.timestamp.max() - df_service_large.timestamp.min(), unit=\"ms\")\n",
    "\n",
    "print(f\"The small data center had a total runtime of {runtime_small}\")\n",
    "print(f\"The large data center had a total runtime of {runtime_large}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "utilization_small = df_host_small.cpu_utilization.mean()\n",
    "utilization_large = df_host_large.cpu_utilization.mean()\n",
    "\n",
    "print(f\"On average, the utilization of each host in the small data center is {utilization_small * 100:.2f}%\")\n",
    "print(f\"On average, the utilization of each host in the large data center is {utilization_large * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sustainability\n",
    "\n",
    "We can also compare the two data centers in terms of sustainabilty\n",
    "\n",
    "Next we print the total energy usage of the two data centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_small = df_power_small.energy_usage.sum() / 3_600_000 # convert energy to kWh\n",
    "energy_large = df_power_large.energy_usage.sum() / 3_600_000 # convert energy to kWh\n",
    "\n",
    "\n",
    "print(f\"The small data center used {energy_small:.2f} kWh during the workload\")\n",
    "print(f\"The large data center used {energy_large:.2f} kWh during the workload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can you think of more metrics to print?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization\n",
    "\n",
    "While single numbers can be great to compare the different workloads, it does not always indicate the reasons for the difference. \n",
    "\n",
    "Similarly to the value aggregation, vizualization can be done directly using the pandas dataframes. \n",
    "However, Graph Greenifier also provides several predefined plotting tools to help this process.\n",
    "\n",
    "### Service\n",
    "\n",
    "Lets start with plotting general information using the service output file. This can be done using the *plotService* function. \n",
    "Below, we plot the number of active servers during the workload. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df_service_small.tasks_active, label=\"small\")\n",
    "plt.plot(df_service_large.tasks_active, label=\"big\")\n",
    "\n",
    "\n",
    "plt.title(\"active tasks during a workload\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hosts\n",
    "\n",
    "We can also look at the performance of the hosts. \n",
    "\n",
    "Lets plot the utilization of the hosts over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHost(df_host, column, aggregation_method, label, window_size=1000):\n",
    "    if aggregation_method not in [\"mean\", \"sum\"]:\n",
    "        raise ValueError(f\"incorrect aggregation method provided: {aggregation_method}, please pick on of [mean, sum]\")\n",
    "\n",
    "    df_agg = df_host.groupby(\"timestamp\")[[column]].agg(aggregation_method)\n",
    "\n",
    "    plt.plot(df_agg.index/1000/60/60, df_agg.rolling(window_size, min_periods=1).mean(), label=label)\n",
    "    plt.xlabel(\"timestamp (h)\")\n",
    "    plt.ylabel(column)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plotHost(df_host_small, \"cpu_utilization\", \"mean\", \"small\")\n",
    "plotHost(df_host_large, \"cpu_utilization\", \"mean\", \"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sustainability\n",
    "\n",
    "We can also plot sustainability related metrics.\n",
    "\n",
    "Lets plot the energy usage over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHost(df_power_small, \"energy_usage\", \"sum\", \"small\")\n",
    "plotHost(df_power_large, \"energy_usage\", \"sum\", \"large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Can you think of other metrics to plot? (Maybe Carbon?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
